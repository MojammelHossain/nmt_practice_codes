{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangVocab:\n",
    "    def __init__(self, lang_name):\n",
    "        \n",
    "        self.name = lang_name\n",
    "        self.token_To_index = {'_sos': 0, '_eos': 1, '_unk': 2, '_pad': 3}\n",
    "        self.index_To_token = {0: '_sos', 1: '_eos', 2: '_unk', 3: '_pad'}\n",
    "        self.token_count = {}\n",
    "        self.num_token = 4\n",
    "        self.max_length = 0\n",
    "    \n",
    "    # Add word into language vocabulary\n",
    "    def word_To_vocab(self, word):\n",
    "        if word not in self.token_To_index:\n",
    "            self.token_To_index[word] = self.num_token\n",
    "            self.index_To_token[self.num_token] = word\n",
    "            self.token_count[word] = 1\n",
    "            self.num_token += 1\n",
    "        else:\n",
    "            self.token_count[word] += 1\n",
    "    \n",
    "    # Divide sentence into word\n",
    "    def sentence_To_word(self, sentence):\n",
    "        length = 0\n",
    "        for word in sentence.split(' '):\n",
    "            self.word_To_vocab(word)\n",
    "            length += 1\n",
    "        self.sentence_length(length)\n",
    "    \n",
    "    # Find the Max length sentence of a language\n",
    "    def sentence_length(self, length):\n",
    "        if self.max_length < length:\n",
    "            self.max_length = length + 1\n",
    "    \n",
    "    # Convert a given sentence into it's corresponding indices vector.\n",
    "    # If padding TRUE then convert small sentence length into max_length\n",
    "    # If word is not present in dictionary the replace it with unknown word token\n",
    "    def sentence_To_vector(self, sentence, padding = False, *max_length):\n",
    "        word_indices = [self.token_To_index['_unk'] if word not in self.token_To_index else self.token_To_index[word] for word in sentence.split(' ')] + [self.token_To_index['_eos']]\n",
    "        if padding == False:\n",
    "            return word_indices\n",
    "        else:\n",
    "            word_indices = self.padding_sentence(word_indices, *max_length)\n",
    "            return word_indices\n",
    "        \n",
    "    # Add pad to convert sentence into max_length size\n",
    "    def padding_sentence(self, word_indices, max_length):\n",
    "        if max_length > len(word_indices):\n",
    "            word_indices = word_indices + [self.token_To_index['_pad'] for _ in range(max_length - len(word_indices))]\n",
    "        return word_indices\n",
    "    \n",
    "    # Choose the most common words\n",
    "    def most_common_words(self, num_words):\n",
    "        self.token_count = Counter(self.token_count).most_common(num_words)\n",
    "        self.token_To_index = {'_sos': 0, '_eos': 1, '_unk': 2, '_pad': 3}\n",
    "        self.index_To_token = {0: '_sos', 1: '_eos', 2: '_unk', 3: '_pad'}\n",
    "        self.num_token = 4\n",
    "        for i in range(len(self.token_count)):\n",
    "            self.token_To_index[self.token_count[i][0]] = self.num_token\n",
    "            self.index_To_token[self.num_token] = self.token_count[i][0]\n",
    "            self.num_token += 1\n",
    "    \n",
    "    # sort the token_To_index and index_To_token dict\n",
    "    def sort_dict(self):\n",
    "        \n",
    "        # sorted dict based on keys\n",
    "        sorted_dict = OrderedDict(sorted(self.token_count.items(), key=lambda t: t[0]))\n",
    "        self.token_To_index = {'_sos': 0, '_eos': 1, '_unk': 2, '_pad': 3}\n",
    "        self.index_To_token = {0: '_sos', 1: '_eos', 2: '_unk', 3: '_pad'}\n",
    "        self.num_token = 4\n",
    "        for key, _ in sorted_dict.items():\n",
    "            self.token_To_index[key] = self.num_token\n",
    "            self.index_To_token[self.num_token] = key\n",
    "            self.num_token += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
